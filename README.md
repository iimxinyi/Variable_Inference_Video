# VideoGenSteps
### Experimental Setup
We conduct real experiments to explore the relationship between inference steps and the video quality.
The experimental platform is built on Ubuntu 20.04 system with an Intel Xeon Platinum 8358 CPU and an NVIDIA RTX A800 GPU.
We use Open-Sora-Plan v1.1.0 as an examplified model of Large Vision Models.

### Experimental Design
The detailed experimental process is as follows. First, we randomly select 5 officially provided prompts, assign 10 random seeds for each prompt, and generate videos using 15 different inference steps ranging from 10 to 80. This setup results in a total of 750 videos.

Prompt 1: a cat wearing sunglasses and working as a lifeguard at pool.

Prompt 2: A corgi vlogging itself in tropical Maui.

Prompt 3: A serene waterfall cascading down moss-covered rocks, its soothing sound creating a harmonious symphony with nature.

Prompt 4: Yellow and black tropical fish dart through the sea.

Prompt 5: A snowy forest landscape with a dirt road running through it. The road is flanked by trees covered in snow, and the ground is also covered in snow. The sun is shining, creating a bright and serene atmosphere. The road appears to be empty, and there are no people or animals visible in the video. The style of the video is a natural landscape shot, with a focus on the beauty of the snowy forest and the peacefulness of the road.

### Experimental Results
OneDrive: https://stuhiteducn-my.sharepoint.com/:u:/g/personal/zhuangxinyi_stu_hit_edu_cn/EdB6sbDqhF5Cl3fDmBlg8zsBqPfs8Xl3UJ7a0M4y7c7PCQ

Baidu Netdisk: 

